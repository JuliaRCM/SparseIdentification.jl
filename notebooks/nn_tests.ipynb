{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # input/output dimension of system\n",
    "# const ndim = 4\n",
    "\n",
    "# # width of hidden layers\n",
    "# const ld = 4\n",
    "\n",
    "# # learning rate\n",
    "# const η = .001\n",
    "\n",
    "# # number of training runs\n",
    "# const runs = 1000\n",
    "\n",
    "# #evaluate neural network\n",
    "# function network(x, model)\n",
    "# \t# input layer\n",
    "# \tlayer0 = tanh.(model[1].W * x)\n",
    "\n",
    "# \t# first hidden layer\n",
    "# \tlayer1 = tanh.(model[2].W * layer0 .+ model[2].b)\n",
    "\t\n",
    "# \t# second hidden layer\n",
    "# \tlayer2 = tanh.(model[3].W * layer1 .+ model[3].b)\n",
    "\n",
    "# \t# output layer (linear activation)\n",
    "# \tmodel[4].W * layer2\n",
    "# end\n",
    "\n",
    "# model = (\n",
    "# \t(W = randn(ld, ndim), ),\n",
    "# \t(W = randn(ld, ld), b = randn(ld)),\n",
    "# \t(W = randn(ld, ld), b = randn(ld)),\n",
    "# \t(W = randn(ndim, ld), ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [1, 2, 3, 4]\n",
    "# network(x, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from Sparsification module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using GeometricIntegrators\n",
    "using Optim\n",
    "using Random\n",
    "using Distances\n",
    "using Symbolics\n",
    "using RuntimeGeneratedFunctions\n",
    "RuntimeGeneratedFunctions.init(@__MODULE__)\n",
    "\n",
    "_prod(a, b, c, arrs...) = a .* _prod(b, c, arrs...)\n",
    "_prod(a, b) = a .* b\n",
    "_prod(a) = a\n",
    "\n",
    "\n",
    "function get_z_vector(dims)\n",
    "    @variables q[1:dims]\n",
    "    @variables p[1:dims]\n",
    "    z = vcat(q,p)\n",
    "    return z\n",
    "end\n",
    "\n",
    "# make combinations of bases of just the order that is given \n",
    "# e.g order = 2 will give just the bases whose powers sum to 2\n",
    "function poly_combos(z, order, inds...)\n",
    "    if order == 0\n",
    "        return Num[1]\n",
    "    elseif order == length(inds)\n",
    "        return [_prod([z[i] for i in inds]...)]\n",
    "    else\n",
    "        start_ind = length(inds) == 0 ? 1 : inds[end]\n",
    "        return vcat([poly_combos(z, order, inds..., j) for j in start_ind:length(z)]...)\n",
    "    end\n",
    "end\n",
    "\n",
    "# gives all bases monomials up to a certain order\n",
    "function primal_monomial_basis(z, order::Int)\n",
    "    return Vector{Symbolics.Num}(vcat([poly_combos(z, i) for i in 1:order]...))\n",
    "end\n",
    "\n",
    "# calculates coefficient bases up to a certain order\n",
    "# mostly for use with trigonometric functions example sin(k*z),\n",
    "# where k is the coefficient\n",
    "function primal_coeff_basis(z, max_coeff::Int)\n",
    "    return Vector{Symbolics.Num}(vcat([k .* z for k in 1:max_coeff]...))\n",
    "end\n",
    "\n",
    "# calculates +,-,*,/ between states as a new basis\n",
    "# the return output is a set to avoid duplicates\n",
    "function primal_operator_basis(z, operator)\n",
    "    return Vector{Symbolics.Num}([operator(z[i], z[j]) for i in 1:length(z)-1 for j in i+1:length(z)] ∪ [operator(z[j], z[i]) for i in 1:length(z)-1 for j in i+1:length(z)])\n",
    "end\n",
    "\n",
    "# calculates power of states as a new basis\n",
    "function primal_power_basis(z, max_power::Int)\n",
    "    if max_power > 0\n",
    "        return Vector{Symbolics.Num}(vcat([z.^i for i in 1:max_power]...))\n",
    "    elseif max_power < 0\n",
    "        return Vector{Symbolics.Num}(vcat([z.^-i for i in 1:abs(max_power)]...))\n",
    "    end\n",
    "end\n",
    "\n",
    "function polynomial_basis(z::Vector{Symbolics.Num} = get_z_vector(2); polyorder::Int = 0, operator=nothing, max_coeff::Int = 0)\n",
    "    primes = primal_monomial_basis(z, polyorder)\n",
    "    primes = vcat(primes, primal_coeff_basis(z, max_coeff))\n",
    "    if operator !== nothing\n",
    "        primes = vcat(primes, primal_operator_basis(z, operator))\n",
    "    end\n",
    "    return primes\n",
    "end\n",
    "\n",
    "function trigonometric_basis(z::Vector{Symbolics.Num} = get_z_vector(2); polyorder::Int = 0, operator=nothing, max_coeff::Int = 0)\n",
    "    primes = polynomial_basis(z, polyorder = polyorder, operator = operator, max_coeff = max_coeff)\n",
    "    return vcat(sin.(primes), cos.(primes))\n",
    "end\n",
    "\n",
    "function exponential_basis(z::Vector{Symbolics.Num} = get_z_vector(2); polyorder::Int = 0, operator=nothing, max_coeff::Int = 0)\n",
    "    primes = polynomial_basis(z, polyorder = polyorder, operator = operator, max_coeff = max_coeff)\n",
    "    return exp.(primes)\n",
    "end\n",
    "\n",
    "function logarithmic_basis(z::Vector{Symbolics.Num} = get_z_vector(2); polyorder::Int = 0, operator=nothing, max_coeff::Int = 0)\n",
    "    primes = polynomial_basis(z, polyorder = polyorder, operator = operator, max_coeff = max_coeff)\n",
    "    return log.(abs.(primes))\n",
    "end\n",
    "\n",
    "function mixed_states_basis(basis::Vector{Symbolics.Num}...)\n",
    "    mixed_states = Tuple(basis)\n",
    "    \n",
    "    ham = Vector{Symbolics.Num}()\n",
    "    for i in eachindex(mixed_states)\n",
    "        for j in i+1:lastindex(mixed_states)\n",
    "            ham = vcat(ham, [mixed_states[i][k] * mixed_states[j][l] for k in 1:length(mixed_states[i]) for l in 1:length(mixed_states[j])])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return Vector{Symbolics.Num}(ham)\n",
    "end\n",
    "\n",
    "# Returns the number of required coefficients for the bases\n",
    "function get_numCoeffs(basis::Vector{Symbolics.Num})\n",
    "    return length(basis)\n",
    "end\n",
    "\n",
    "# gets a vector of combinations of basis\n",
    "function get_basis_set(bases::Vector{Symbolics.Num}...)\n",
    "    # gets a vector of combinations of basis\n",
    "    basis = vcat(bases...)\n",
    "    \n",
    "    # removes duplicates\n",
    "    basis = Vector{Symbolics.Num}(collect(unique(basis)))\n",
    "\n",
    "    return basis\n",
    "end\n",
    "\n",
    "function ΔH_func_builder(d::Int, z::Vector{Symbolics.Num} = get_z_vector(d), bases::Vector{Symbolics.Num}...) \n",
    "    # nd is the total number of dimensions of all the states, e.g. if q,p each of 3 dims, that is 6 dims in total\n",
    "    nd = 2d\n",
    "    Dz = Differential.(z)\n",
    "    \n",
    "    # collects and sums combinations of basis and coefficients\"\n",
    "    basis = get_basis_set(bases...)\n",
    "   \n",
    "    # gets number of terms in the basis\n",
    "    @variables a[1:get_numCoeffs(basis)]\n",
    "    \n",
    "    # collect and sum combinations of basis and coefficients\n",
    "    ham = sum(collect(a .* basis))\n",
    "    \n",
    "    # gives derivative of the hamiltonian, but not the skew-symmetric true one\n",
    "    f = [expand_derivatives(dz(ham)) for dz in Dz]\n",
    "    \n",
    "    # line below makes the vector into a hamiltonian vector field by multiplying with the skew-symmetric matrix\n",
    "    ∇H = vcat(f[d+1:2d], -f[1:d])\n",
    "    \n",
    "    # builds a function that calculates Hamiltonian gradient and converts the function to a native Julia function\n",
    "    ∇H_eval = @RuntimeGeneratedFunction(Symbolics.inject_registered_module_functions(build_function(∇H, z, a)[2]))\n",
    "    \n",
    "    return ∇H_eval\n",
    "end\n",
    "\n",
    "struct HamiltonianSINDy{T, GHT} \n",
    "    basis::Vector{Symbolics.Num} # the augmented basis for sparsification\n",
    "    analytical_fθ::GHT\n",
    "    z::Vector{Symbolics.Num} \n",
    "    λ::T # Sparsification Parameter\n",
    "    noise_level::T # Noise amplitude added to the data\n",
    "    noiseGen_timeStep::T # Time step for the integrator to get noisy data \n",
    "    nloops::Int # Sparsification Loops\n",
    "    \n",
    "    function HamiltonianSINDy(basis::Vector{Symbolics.Num},\n",
    "        analytical_fθ::GHT = missing,\n",
    "        z::Vector{Symbolics.Num} = get_z_vector(2);\n",
    "        λ::T = 0.05,\n",
    "        noise_level::T = 0.01,\n",
    "        noiseGen_timeStep::T = 0.05,\n",
    "        nloops = 10) where {T, GHT <: Union{Base.Callable,Missing}}\n",
    "\n",
    "        new{T, GHT}(basis, analytical_fθ, z, λ, noise_level, noiseGen_timeStep, nloops)\n",
    "    end\n",
    "end\n",
    "\n",
    "function gen_noisy_ref_data(method::HamiltonianSINDy, x)\n",
    "    # initialize timestep data for analytical solution\n",
    "    tstep = method.noiseGen_timeStep\n",
    "    tspan = (zero(tstep), tstep)\n",
    "\n",
    "    function next_timestep(x)\n",
    "        prob_ref = ODEProblem((dx, t, x, params) -> method.analytical_fθ(dx, x, params, t), tspan, tstep, x)\n",
    "        sol = integrate(prob_ref, Gauss(2))\n",
    "        sol.q[end]\n",
    "    end\n",
    "\n",
    "    data_ref = [next_timestep(_x) for _x in x]\n",
    "\n",
    "    # add noise\n",
    "    data_ref_noisy = [_x .+ method.noise_level .* randn(size(_x)) for _x in data_ref]\n",
    "\n",
    "    return data_ref_noisy\n",
    "\n",
    "end\n",
    "\n",
    "struct TrainingData{AT<:AbstractArray}\n",
    "    x::AT # initial condition\n",
    "    ẋ::AT # initial condition\n",
    "    y::AT # noisy data at next time step\n",
    "\n",
    "    TrainingData(x::AT, ẋ::AT, y::AT) where {AT} = new{AT}(x, ẋ, y)\n",
    "    TrainingData(x::AT, ẋ::AT) where {AT} = new{AT}(x, ẋ)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct HamiltonianSINDyVectorField{DT,CT,GHT}\n",
    "    # basis::BT\n",
    "    coefficients::CT\n",
    "    fθ::GHT\n",
    "\n",
    "    function HamiltonianSINDyVectorField(coefficients::CT, fθ::GHT) where {DT, CT <: AbstractVector{DT}, GHT <: Base.Callable}\n",
    "        new{DT,CT,GHT}(coefficients, fθ)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function VectorField(method::HamiltonianSINDy, data::TrainingData; solver = Newton())\n",
    "    # TODO: Check that first dimension x is even\n",
    "\n",
    "    # dimension of system\n",
    "    d = size(data.x[begin], 1) ÷ 2\n",
    "\n",
    "    # returns function that builds hamiltonian gradient through symbolics\n",
    "    fθ = ΔH_func_builder(d, method.z, method.basis)\n",
    "\n",
    "    # Compute Sparse Regression\n",
    "    #TODO: make sparsify method choosable through arguments\n",
    "    # coeffs = sparsify_two(method, fθ, data.x, data.y, solver)\n",
    "    coeffs = sparsify_parallel(method, fθ, data.x, data.y, solver)\n",
    "    # coeffs = sparsify(method, fθ, data.x, data.ẋ, solver)\n",
    "    # coeffs = sparsify_parallel_encoder(method, fθ, data, solver)\n",
    "    \n",
    "    HamiltonianSINDyVectorField(coeffs, fθ)\n",
    "end\n",
    "\n",
    "\n",
    "\" wrapper function for generalized SINDY hamiltonian gradient.\n",
    "Needs the output of fθ to work! \"\n",
    "function (vectorfield::HamiltonianSINDyVectorField)(dz, z)\n",
    "    vectorfield.fθ(dz, z, vectorfield.coefficients)\n",
    "    return dz\n",
    "end\n",
    "\n",
    "(vectorfield::HamiltonianSINDyVectorField)(dz, z, p, t) = vectorfield(dz, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up...\n",
      "Generate Training Data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingData{Vector{Vector{Float64}}}([[-20.0, -20.0, -20.0, -20.0], [-15.555555555555557, -20.0, -20.0, -20.0], [-11.11111111111111, -20.0, -20.0, -20.0], [-6.66666666666667, -20.0, -20.0, -20.0], [-2.2222222222222214, -20.0, -20.0, -20.0], [2.2222222222222214, -20.0, -20.0, -20.0], [6.666666666666664, -20.0, -20.0, -20.0], [11.11111111111111, -20.0, -20.0, -20.0], [15.555555555555555, -20.0, -20.0, -20.0], [20.0, -20.0, -20.0, -20.0]  …  [-20.0, 20.0, 20.0, 20.0], [-15.555555555555557, 20.0, 20.0, 20.0], [-11.11111111111111, 20.0, 20.0, 20.0], [-6.66666666666667, 20.0, 20.0, 20.0], [-2.2222222222222214, 20.0, 20.0, 20.0], [2.2222222222222214, 20.0, 20.0, 20.0], [6.666666666666664, 20.0, 20.0, 20.0], [11.11111111111111, 20.0, 20.0, 20.0], [15.555555555555555, 20.0, 20.0, 20.0], [20.0, 20.0, 20.0, 20.0]], [[-20.0, -20.0, -0.9129452507276277, -0.9129452507276277], [-20.0, -20.0, -0.1518183733999112, -0.9129452507276277], [-20.0, -20.0, 0.9933330424549106, -0.9129452507276277], [-20.0, -20.0, -0.3741512305712224, -0.9129452507276277], [-20.0, -20.0, -0.7952200570230497, -0.9129452507276277], [-20.0, -20.0, 0.7952200570230497, -0.9129452507276277], [-20.0, -20.0, 0.37415123057121746, -0.9129452507276277], [-20.0, -20.0, -0.9933330424549106, -0.9129452507276277], [-20.0, -20.0, 0.15181837339991294, -0.9129452507276277], [-20.0, -20.0, 0.9129452507276277, -0.9129452507276277]  …  [20.0, 20.0, -0.9129452507276277, 0.9129452507276277], [20.0, 20.0, -0.1518183733999112, 0.9129452507276277], [20.0, 20.0, 0.9933330424549106, 0.9129452507276277], [20.0, 20.0, -0.3741512305712224, 0.9129452507276277], [20.0, 20.0, -0.7952200570230497, 0.9129452507276277], [20.0, 20.0, 0.7952200570230497, 0.9129452507276277], [20.0, 20.0, 0.37415123057121746, 0.9129452507276277], [20.0, 20.0, -0.9933330424549106, 0.9129452507276277], [20.0, 20.0, 0.15181837339991294, 0.9129452507276277], [20.0, 20.0, 0.9129452507276277, 0.9129452507276277]], [[-21.00121076471114, -21.00121076471114, -20.047772627129874, -20.047772627129874], [-16.555340544527574, -21.00121076471114, -19.983674466479087, -20.047772627129874], [-12.110013966511522, -21.00121076471114, -19.96085166165958, -20.047772627129874], [-7.667462585936573, -21.00121076471114, -20.03705332876249, -20.047772627129874], [-3.222897627667322, -21.00121076471114, -20.019504491006213, -20.047772627129874], [1.223375801916921, -21.00121076471114, -19.95261544516677, -20.047772627129874], [5.666731473375476, -21.00121076471114, -20.005569620813517, -20.047772627129874], [10.109923381086732, -21.00121076471114, -20.044420241430192, -20.047772627129874], [14.556119725831481, -21.00121076471114, -19.97090568644537, -20.047772627129874], [19.000889288699206, -21.00121076471114, -19.97096125494406, -20.047772627129874]  …  [-19.000889288699206, 21.00121076471114, 19.97096125494406, 20.047772627129874], [-14.556119725831483, 21.00121076471114, 19.97090568644537, 20.047772627129874], [-10.109923381086732, 21.00121076471114, 20.044420241430192, 20.047772627129874], [-5.666731473375481, 21.00121076471114, 20.005569620813517, 20.047772627129874], [-1.223375801916921, 21.00121076471114, 19.95261544516677, 20.047772627129874], [3.222897627667322, 21.00121076471114, 20.019504491006213, 20.047772627129874], [7.667462585936567, 21.00121076471114, 20.03705332876249, 20.047772627129874], [12.110013966511522, 21.00121076471114, 19.96085166165958, 20.047772627129874], [16.555340544527574, 21.00121076471114, 19.983674466479087, 20.047772627129874], [21.00121076471114, 21.00121076471114, 20.047772627129874, 20.047772627129874]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --------------------\n",
    "# Setup\n",
    "# --------------------\n",
    "\n",
    "println(\"Setting up...\")\n",
    "\n",
    "# 2D system with 4 variables [q₁, q₂, p₁, p₂]\n",
    "nd = 4\n",
    "\n",
    "z = get_z_vector(nd/2)\n",
    "polynomial = polynomial_basis(z, polyorder=3)\n",
    "trigonometric  = trigonometric_basis(z, max_coeff=1)\n",
    "prime_diff = primal_operator_basis(z, -)\n",
    "basis = get_basis_set(polynomial, trigonometric, prime_diff)\n",
    "# initialize analytical function, keep λ smaller than ϵ so system is identifiable\n",
    "ϵ = 0.5\n",
    "m = 1\n",
    "\n",
    "# two-dim simple harmonic oscillator (not used anywhere only in case some testing needed)\n",
    "# H_ana(x, p, t) = ϵ * x[1]^2 + ϵ * x[2]^2 + 1/(2*m) * x[3]^2 + 1/(2*m) * x[4]^2\n",
    "# H_ana(x, p, t) = cos(x[1]) + cos(x[2]) + 1/(2*m) * x[3]^2 + 1/(2*m) * x[4]^2\n",
    "\n",
    "# Gradient function of the 2D hamiltonian\n",
    "# grad_H_ana(x) = [x[3]; x[4]; -2ϵ * x[1]; -2ϵ * x[2]]\n",
    "grad_H_ana(x) = [x[3]; x[4]; sin(x[1]); sin(x[2])]\n",
    "function grad_H_ana!(dx, x, p, t)\n",
    "    dx .= grad_H_ana(x)\n",
    "end\n",
    "# ------------------------------------------------------------\n",
    "# Training Data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "println(\"Generate Training Data...\")\n",
    "\n",
    "# number of samples\n",
    "num_samp = 10\n",
    "\n",
    "# samples in p and q space\n",
    "samp_range = LinRange(-20, 20, num_samp)\n",
    "\n",
    "# initialize vector of matrices to store ODE solve output\n",
    "\n",
    "# s depend on size of nd (total dims), 4 in the case here so we use samp_range x samp_range x samp_range x samp_range\n",
    "s = collect(Iterators.product(fill(samp_range, nd)...))\n",
    "\n",
    "\n",
    "# compute vector field from x state values\n",
    "x = [collect(s[i]) for i in eachindex(s)]\n",
    "dx = zeros(nd)\n",
    "p = 0\n",
    "t = 0\n",
    "ẋ = [grad_H_ana!(copy(dx), _x, p, t) for _x in x]\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Compute Sparse Regression\n",
    "# ----------------------------------------\n",
    "\n",
    "# choose SINDy method\n",
    "# (λ parameter must be close to noise value so that only coeffs with value around the noise are sparsified away)\n",
    "# noiseGen_timeStep chosen randomly for now\n",
    "method = HamiltonianSINDy(basis, grad_H_ana!, z, λ = 0.05, noise_level = 0.00, noiseGen_timeStep = 0.05)\n",
    "\n",
    "# generate noisy references data at next time step\n",
    "y = gen_noisy_ref_data(method, x)\n",
    "\n",
    "# collect training data\n",
    "tdata = TrainingData(x, ẋ, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RuntimeGeneratedFunction(#=in Main=#, #=using Main=#, :((ˍ₋out, ˍ₋arg1, a)->begin\n",
       "          #= C:\\Users\\nigel\\.julia\\packages\\SymbolicUtils\\H684H\\src\\code.jl:350 =#\n",
       "          #= C:\\Users\\nigel\\.julia\\packages\\SymbolicUtils\\H684H\\src\\code.jl:351 =#\n",
       "          #= C:\\Users\\nigel\\.julia\\packages\\SymbolicUtils\\H684H\\src\\code.jl:352 =#\n",
       "          begin\n",
       "              begin\n",
       "                  #= C:\\Users\\nigel\\.julia\\packages\\Symbolics\\3jLt1\\src\\build_function.jl:520 =#\n",
       "                  #= C:\\Users\\nigel\\.julia\\packages\\SymbolicUtils\\H684H\\src\\code.jl:399 =# @inbounds begin\n",
       "                          #= C:\\Users\\nigel\\.julia\\packages\\SymbolicUtils\\H684H\\src\\code.jl:395 =#\n",
       "                          ˍ₋out[1] = (+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((*)((cos)(ˍ₋arg1[3]), (getindex)(a, 37)), (*)(-1, (getindex)(a, 44))), (*)(-1, (getindex)(a, 46))), (*)(-1, (getindex)(a, 54))), (*)((^)(ˍ₋arg1[4], 2), (getindex)(a, 33))), (*)((^)(ˍ₋arg1[1], 2), (getindex)(a, 17))), (*)((^)(ˍ₋arg1[2], 2), (getindex)(a, 26))), (*)((getindex)(a, 7), ˍ₋arg1[1])), (*)((getindex)(a, 13), ˍ₋arg1[4])), (*)((getindex)(a, 10), ˍ₋arg1[2])), (*)((*)(3, (^)(ˍ₋arg1[3], 2)), (getindex)(a, 31))), (*)((*)(-1, (sin)(ˍ₋arg1[3])), (getindex)(a, 41))), (*)((*)(2, (getindex)(a, 12)), ˍ₋arg1[3])), (*)((*)((getindex)(a, 20), ˍ₋arg1[1]), ˍ₋arg1[2])), (*)((*)((getindex)(a, 23), ˍ₋arg1[4]), ˍ₋arg1[1])), (*)((*)((getindex)(a, 29), ˍ₋arg1[4]), ˍ₋arg1[2])), (*)((*)((*)(2, (getindex)(a, 32)), ˍ₋arg1[3]), ˍ₋arg1[4])), (*)((*)((*)(2, (getindex)(a, 22)), ˍ₋arg1[3]), ˍ₋arg1[1])), (*)((*)((*)(2, (getindex)(a, 28)), ˍ₋arg1[3]), ˍ₋arg1[2])), (getindex)(a, 3)), (getindex)(a, 48)), (getindex)(a, 50)), (getindex)(a, 52))\n",
       "                          ˍ₋out[2] = (+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((*)((^)(ˍ₋arg1[1], 2), (getindex)(a, 18)), (*)((^)(ˍ₋arg1[3], 2), (getindex)(a, 32))), (*)((^)(ˍ₋arg1[2], 2), (getindex)(a, 27))), (*)((cos)(ˍ₋arg1[4]), (getindex)(a, 38))), (*)(-1, (getindex)(a, 45))), (*)(-1, (getindex)(a, 47))), (*)(-1, (getindex)(a, 48))), (*)((getindex)(a, 8), ˍ₋arg1[1])), (*)((getindex)(a, 11), ˍ₋arg1[2])), (*)((getindex)(a, 13), ˍ₋arg1[3])), (*)((*)(2, (getindex)(a, 14)), ˍ₋arg1[4])), (*)((*)(3, (^)(ˍ₋arg1[4], 2)), (getindex)(a, 34))), (*)((*)(-1, (sin)(ˍ₋arg1[4])), (getindex)(a, 42))), (*)((*)((getindex)(a, 21), ˍ₋arg1[1]), ˍ₋arg1[2])), (*)((*)((getindex)(a, 23), ˍ₋arg1[3]), ˍ₋arg1[1])), (*)((*)((getindex)(a, 29), ˍ₋arg1[3]), ˍ₋arg1[2])), (*)((*)((*)(2, (getindex)(a, 33)), ˍ₋arg1[3]), ˍ₋arg1[4])), (*)((*)((*)(2, (getindex)(a, 24)), ˍ₋arg1[4]), ˍ₋arg1[1])), (*)((*)((*)(2, (getindex)(a, 30)), ˍ₋arg1[4]), ˍ₋arg1[2])), (getindex)(a, 4)), (getindex)(a, 51)), (getindex)(a, 53)), (getindex)(a, 54))\n",
       "                          ˍ₋out[3] = (+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((*)(-1, (getindex)(a, 1)), (*)((sin)(ˍ₋arg1[1]), (getindex)(a, 39))), (*)(-1, (getindex)(a, 43))), (*)(-1, (getindex)(a, 44))), (*)(-1, (getindex)(a, 45))), (*)((*)(-1, (^)(ˍ₋arg1[3], 2)), (getindex)(a, 22))), (*)((*)(-1, (^)(ˍ₋arg1[2], 2)), (getindex)(a, 19))), (*)((*)(-1, (getindex)(a, 6)), ˍ₋arg1[2])), (*)((*)(-2, (getindex)(a, 5)), ˍ₋arg1[1])), (*)((*)(-3, (^)(ˍ₋arg1[1], 2)), (getindex)(a, 15))), (*)((*)(-1, (^)(ˍ₋arg1[4], 2)), (getindex)(a, 24))), (*)((*)(-1, (cos)(ˍ₋arg1[1])), (getindex)(a, 35))), (*)((*)(-1, (getindex)(a, 7)), ˍ₋arg1[3])), (*)((*)(-1, (getindex)(a, 8)), ˍ₋arg1[4])), (*)((*)((*)(-2, (getindex)(a, 17)), ˍ₋arg1[3]), ˍ₋arg1[1])), (*)((*)((*)(-1, (getindex)(a, 20)), ˍ₋arg1[3]), ˍ₋arg1[2])), (*)((*)((*)(-1, (getindex)(a, 23)), ˍ₋arg1[3]), ˍ₋arg1[4])), (*)((*)((*)(-1, (getindex)(a, 21)), ˍ₋arg1[4]), ˍ₋arg1[2])), (*)((*)((*)(-2, (getindex)(a, 18)), ˍ₋arg1[4]), ˍ₋arg1[1])), (*)((*)((*)(-2, (getindex)(a, 16)), ˍ₋arg1[1]), ˍ₋arg1[2])), (getindex)(a, 49)), (getindex)(a, 50)), (getindex)(a, 51))\n",
       "                          ˍ₋out[4] = (+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((+)((*)(-1, (getindex)(a, 2)), (*)(-1, (getindex)(a, 49))), (*)((sin)(ˍ₋arg1[2]), (getindex)(a, 40))), (*)(-1, (getindex)(a, 46))), (*)(-1, (getindex)(a, 47))), (*)((*)(-1, (^)(ˍ₋arg1[3], 2)), (getindex)(a, 28))), (*)((*)(-1, (^)(ˍ₋arg1[1], 2)), (getindex)(a, 16))), (*)((*)(-3, (^)(ˍ₋arg1[2], 2)), (getindex)(a, 25))), (*)((*)(-1, (^)(ˍ₋arg1[4], 2)), (getindex)(a, 30))), (*)((*)(-1, (cos)(ˍ₋arg1[2])), (getindex)(a, 36))), (*)((*)(-1, (getindex)(a, 6)), ˍ₋arg1[1])), (*)((*)(-1, (getindex)(a, 10)), ˍ₋arg1[3])), (*)((*)(-2, (getindex)(a, 9)), ˍ₋arg1[2])), (*)((*)(-1, (getindex)(a, 11)), ˍ₋arg1[4])), (*)((*)((*)(-1, (getindex)(a, 20)), ˍ₋arg1[3]), ˍ₋arg1[1])), (*)((*)((*)(-2, (getindex)(a, 26)), ˍ₋arg1[3]), ˍ₋arg1[2])), (*)((*)((*)(-1, (getindex)(a, 21)), ˍ₋arg1[4]), ˍ₋arg1[1])), (*)((*)((*)(-2, (getindex)(a, 27)), ˍ₋arg1[4]), ˍ₋arg1[2])), (*)((*)((*)(-1, (getindex)(a, 29)), ˍ₋arg1[3]), ˍ₋arg1[4])), (*)((*)((*)(-2, (getindex)(a, 19)), ˍ₋arg1[1]), ˍ₋arg1[2])), (getindex)(a, 43)), (getindex)(a, 52)), (getindex)(a, 53))\n",
       "                          #= C:\\Users\\nigel\\.julia\\packages\\SymbolicUtils\\H684H\\src\\code.jl:397 =#\n",
       "                          nothing\n",
       "                      end\n",
       "              end\n",
       "          end\n",
       "      end))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dimension of system\n",
    "d = size(tdata.x[begin], 1) ÷ 2\n",
    "\n",
    "# returns function that builds hamiltonian gradient through symbolics\n",
    "fθ = ΔH_func_builder(d, method.z, method.basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((W = [-0.4940019128346206 0.09752468328156615 1.331578016230588 -0.20292327002091207; 1.0508045233474548 0.562582399634259 0.7766634643103753 0.32896203956253534; -0.5557696326381378 -1.2481492543397241 -1.094763897321301 -1.1971504151081356; -0.4758794012849007 0.3111896416850261 1.2150738574101774 -0.9713389451406967],), (W = [0.6228894676539797 -0.3523209295700162 0.03872303500267631 -2.0680877322938622; 0.6950920129222059 0.46192371922110653 0.8606743727326654 -0.19324242873678746; -1.523031345297429 1.7785063085186315 -0.1652217201543841 0.07972215585952311; 1.7254730509606304 -0.07890337274202382 1.85526847158796 -1.9142442957089896], b = [-0.6857378993056897, 0.20532056674221225, 1.686127974916049, 0.15750112532370059]), (W = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],), (W = [0.3472449093583463 -0.020971406276601153 -0.42272252135545524 -0.4635353215136673; -0.24806651582471337 -1.5716392671841364 0.5997844789041654 -1.6714294452345042; -0.36777887905936985 1.6970448772406943 1.6573768396546567 -1.576922255191032; 0.182082383205961 -1.1919998092070714 0.2132580698295217 0.8797797275011311],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# latent dimension: ld\n",
    "ld = 4\n",
    "ndim = size(tdata.x[begin], 1)\n",
    "model = (\n",
    "\t(W = randn(ld, ndim), ),\n",
    "\t(W = randn(ld, ld), b = randn(ld)),\n",
    "\t(W = zeros(get_numCoeffs(method.basis)), ),\n",
    "\t(W = randn(ndim, ld), ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network_two (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# evaluate neural network\n",
    "function network_two(xᵢₙ, model, method, fθ, solver)\n",
    "\t# input layer\n",
    "\tinput_layer = tanh.(model[1].W * xᵢₙ)\n",
    "\n",
    "\t# first hidden layer\n",
    "\tx₀ = tanh.(model[2].W * input_layer .+ model[2].b)\n",
    "\t\n",
    "\t# SINDy layer\n",
    "\tfunction SINDy_layer()\n",
    "        # coeffs initialized to a vector of zeros b/c easier to optimize zeros for our case\n",
    "        coeffs = model[3].W\n",
    "\n",
    "        numLoops = 4 # random choice of loop steps\n",
    "        \n",
    "        local x̄ = zeros(eltype(coeffs), axes(x₀))\n",
    "        local x̃ = zeros(eltype(coeffs), axes(x₀))\n",
    "        local f = zeros(eltype(coeffs), axes(x₀))\n",
    "\n",
    "        # gradient at current (x) values\n",
    "        fθ(f, x₀, coeffs)\n",
    "\n",
    "        # for first guess use explicit euler\n",
    "        x̃ .= x₀ .+ method.noiseGen_timeStep .* f\n",
    "        \n",
    "        for _ in 1:numLoops\n",
    "            x̄ .= (x₀ .+ x̃) ./ 2\n",
    "            # find gradient at {(x̃ₙ + x̃ⁱₙ₊₁)/2} to get Hermite extrapolation\n",
    "            fθ(f, x̄, coeffs)\n",
    "            # mid point rule for integration to next step\n",
    "            x̃ .= x₀ .+ method.noiseGen_timeStep .* f\n",
    "        end\n",
    "        return x̃\n",
    "    end\n",
    "\n",
    "\t# output layer (linear activation)\n",
    "\treturn model[4].W * SINDy_layer()\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xᵢₙ = tdata.x[1]\n",
    "# network_two(xᵢₙ, model, method, fθ, Newton())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_kernel (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loss_kernel(xᵢₙ, x₁, model, method, fθ, solver)\n",
    "    x̃₁ = network_two(xᵢₙ, model, method, fθ, solver)\n",
    "    # calculate square Euclidean distance\n",
    "    sqeuclidean(x̃₁, x₁)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define loss function\n",
    "function loss(coeffs::AbstractVector)\n",
    "    # Convert the flattened parameters back to the original structure\n",
    "    reconstructed_model = (\n",
    "        (W = reshape(coeffs[1:ld*ndim], ld, ndim), ),\n",
    "        (W = reshape(coeffs[ld*ndim+1:ld*(ld+ndim)], ld, ld), b = reshape(coeffs[ld*(ld+ndim)+1:ld*(ld+ndim)+ld], ld)),\n",
    "        (W = coeffs[ld*(ld+ndim)+ld+1:ld*(ld+ndim)+ld+get_numCoeffs(method.basis)], ),\n",
    "        (W = reshape(coeffs[ld*(ld+ndim)+ld+get_numCoeffs(method.basis)+1:end], ndim, ld), ),\n",
    "    )\n",
    "\n",
    "    mapreduce(z -> loss_kernel(z..., reconstructed_model, method, fθ, solver), +, zip(tdata.x, tdata.y))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106-element Vector{Float64}:\n",
       " -0.4940019128346206\n",
       "  1.0508045233474548\n",
       " -0.5557696326381378\n",
       " -0.4758794012849007\n",
       "  0.09752468328156615\n",
       "  0.562582399634259\n",
       " -1.2481492543397241\n",
       "  0.3111896416850261\n",
       "  1.331578016230588\n",
       "  0.7766634643103753\n",
       "  ⋮\n",
       " -1.1919998092070714\n",
       " -0.42272252135545524\n",
       "  0.5997844789041654\n",
       "  1.6573768396546567\n",
       "  0.2132580698295217\n",
       " -0.4635353215136673\n",
       " -1.6714294452345042\n",
       " -1.576922255191032\n",
       "  0.8797797275011311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coeffs = [model[1].W, model[2].W, model[2].b, model[3].W, model[4].W]\n",
    "using LinearAlgebra\n",
    "\n",
    "# Flatten the model into a single vector\n",
    "flattened_model = cat([vec(coeffs[i]) for i in 1:length(coeffs)]..., dims=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Guess..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iter     Function value   Gradient norm \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     6.123124e+06     1.814828e+05\n",
      " * time: 0.018000125885009766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1     5.537703e+06     1.476226e+05\n",
      " * time: 24.60199999809265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2     4.881667e+06     1.122941e+05\n",
      " * time: 50.93900012969971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3     4.114988e+06     8.854054e+04\n",
      " * time: 74.24100017547607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4     3.520571e+06     1.447283e+05\n",
      " * time: 100.65900015830994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5     3.392431e+06     9.206898e+04\n",
      " * time: 123.90400004386902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     6     3.246096e+06     8.558427e+04\n",
      " * time: 150.86600017547607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     7     3.120481e+06     7.889838e+04\n",
      " * time: 180.3270001411438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     8     3.005576e+06     6.576877e+04\n",
      " * time: 208.43200016021729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9     2.928176e+06     6.741656e+04\n",
      " * time: 234.9430000782013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10     2.739542e+06     6.356774e+04\n",
      " * time: 265.50800013542175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    11     2.695393e+06     1.055378e+05\n",
      " * time: 295.35199999809265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    12     2.639809e+06     7.977781e+04\n",
      " * time: 328.4670000076294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    13     2.431054e+06     6.369389e+04\n",
      " * time: 360.728000164032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    14     2.419894e+06     7.030843e+04\n",
      " * time: 384.6340000629425\n"
     ]
    }
   ],
   "source": [
    "# initial guess\n",
    "println(\"Initial Guess...\")\n",
    "# Define the optimization solver\n",
    "solver = BFGS()\n",
    "result = Optim.optimize(loss, flattened_model, solver, Optim.Options(show_trace=true); autodiff = :forward)\n",
    "\n",
    "coeffs .= result.minimizer\n",
    "\n",
    "println(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
